@{
	Layout = null;
}
<!doctype html>
<html>
<head>
	<style>
		/* CSS comes here */
		body {
			font-family: arial;
		}

		button {
			padding: 10px;
			background-color: #6a67ce;
			color: #FFFFFF;
			border: 0px;
			cursor: pointer;
			border-radius: 5px;
		}

		#output {
			background-color: #F9F9F9;
			padding: 10px;
			width: 100%;
			margin-top: 20px;
			line-height: 30px;
		}

		.hide {
			display: none;
		}

		.show {
			display: block;
		}

		button {
			margin: 10px 5px;
		}

		li {
			margin: 10px;
		}

		body {
			width: 90%;
			max-width: 960px;
			margin: 0px auto;
		}

		#btns {
			display: none;
		}

		h1 {
			margin: 100px;
		}

	</style>
	<title>JavaScript Speech to Text</title>
</head>
<body>
	<h2>JavaScript Speech to Text</h2>
	<div id="spch">
	<p>Click on the below button and speak something...</p>
	<p><button type="button" onclick="runSpeechRecognition()">Speech to Text</button> &nbsp; <span id="action"></span></p>
	</div>
	<div id="spch-no-support" style="display:none;">
		<p>speech recog not supported......</p>
	</div>
	<div id="output" class="hide"></div>

	<h1> MediaRecorder API example</h1>

	<p> For now it is supported only in Firefox(v25+) and Chrome(v47+)</p>
	<div id='gUMArea'>
		<div>
			Record:
			<input type="radio" name="media" value="video" checked id='mediaVideo'>Video
			<input type="radio" name="media" value="audio">audio
		</div>
		<button class="btn btn-default" id='gUMbtn'>Request Stream</button>
	</div>
	<div id='btns'>
		<button class="btn btn-default" id='start'>Start</button>
		<button class="btn btn-default" id='stop'>Stop</button>
	</div>
	<div>
		<ul class="list-unstyled" id='ul'></ul>
	</div>
	<script src="https://code.jquery.com/jquery-2.2.0.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
	<script>
		'use strict'

let log = console.log.bind(console),
  id = val => document.getElementById(val),
  ul = id('ul'),
  gUMbtn = id('gUMbtn'),
  start = id('start'),
  stop = id('stop'),
  stream,
  recorder,
  counter=1,
  chunks,
  media;


gUMbtn.onclick = e => {
  let mv = id('mediaVideo'),
      mediaOptions = {
        video: {
          tag: 'video',
          type: 'video/webm',
          ext: '.mp4',
          gUM: {video: true, audio: true}
        },
        audio: {
          tag: 'audio',
          type: 'audio/ogg',
          ext: '.ogg',
          gUM: {audio: true}
        }
      };
  media = mv.checked ? mediaOptions.video : mediaOptions.audio;
  navigator.mediaDevices.getUserMedia(media.gUM).then(_stream => {
    stream = _stream;
    id('gUMArea').style.display = 'none';
    id('btns').style.display = 'inherit';
    start.removeAttribute('disabled');
    recorder = new MediaRecorder(stream);
    recorder.ondataavailable = e => {
      chunks.push(e.data);
      if(recorder.state == 'inactive')  makeLink();
    };
    log('got media successfully');
  }).catch(log);
}

start.onclick = e => {
  start.disabled = true;
  stop.removeAttribute('disabled');
  chunks=[];
  recorder.start();
}


stop.onclick = e => {
  stop.disabled = true;
  recorder.stop();
  start.removeAttribute('disabled');
}



function makeLink(){
  let blob = new Blob(chunks, {type: media.type })
    , url = URL.createObjectURL(blob)
    , li = document.createElement('li')
    , mt = document.createElement(media.tag)
    , hf = document.createElement('a')
  ;
  mt.controls = true;
  mt.src = url;
  hf.href = url;
  hf.download = `${counter++}${media.ext}`;
  hf.innerHTML = `donwload ${hf.download}`;
  li.appendChild(mt);
  li.appendChild(hf);
  ul.appendChild(li);
}
	</script>

	<script>
		
		/* JS comes here */
		function runSpeechRecognition() {
			// get output div reference
			var output = document.getElementById("output");
			// get action element reference
			var action = document.getElementById("action");
			// new speech recognition object
			var SpeechRecognition = SpeechRecognition || webkitSpeechRecognition;
			var recognition = new SpeechRecognition();

			// This runs when the speech recognition service starts
			recognition.onstart = function () {
				action.innerHTML = "<small>listening, please speak...</small>";
			};

			recognition.onspeechend = function () {
				action.innerHTML = "<small>stopped listening, hope you are done...</small>";
				recognition.stop();
			}

			// This runs when the speech recognition service returns result
			recognition.onresult = function (event) {
				var transcript = event.results[0][0].transcript;
				var confidence = event.results[0][0].confidence;
				output.innerHTML = "<b>Text:</b> " + transcript + "<br/> <b>Confidence:</b> " + confidence * 100 + "%";
				output.classList.remove("hide");
			};

			// start recognition
			recognition.start();
		}

		if (typeof (SpeechRecognition) == 'undefined' && typeof (webkitSpeechRecognition) == 'undefined') {
			document.querySelector("#spch-no-support").style.display = "";
			document.querySelector("#spch").style.display = "none";
		}
	</script>
</body>
</html>